# mutinode-distributed-gpu-inference
<br />
meant to be used short term as a local gpu cluster on the NERVE robotics piplines. these require various models/algorithms to be trained and often run into Cuda Out of Memory errors
<br />
will start with attempting to get SAM2 to work across multiple GPUs with tensor-parallelism on attn heads
<br />
previous versions: not useful for anything, i just left them in case i want to use some of the code (probably not except for v1)
