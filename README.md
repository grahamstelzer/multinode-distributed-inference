# mutinode-distributed-gpu-inference
Meant to be used short term as essentially a local gpu cluster on the NERVE robotics piplines. These require various models/algorithms to be trained on GPUs and often run into Cuda Out of Memory errors.
<br />
Controllable through config.json.
<br />
Future: customize tensor splits with cuda code in extensions.